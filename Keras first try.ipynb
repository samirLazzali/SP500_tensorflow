{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de ce model est de prédire à partir d'autres stock une certaine stock afin de définir une potentielle anomalie niveau comportement par rapport aux autres stock. Nous avons choisi d'utiliser keras qui est l'API de tensorflow et plus user friendly surtout dans l'initialisation de l'architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_csv('data_stocks.csv')\n",
    "# Drop date variable\n",
    "data = data.drop(['DATE'], 1)\n",
    "# Dimensions of dataset\n",
    "n = data.shape[0]\n",
    "p = data.shape[1]\n",
    "# Make data a numpy array\n",
    "df = data\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sépare notre base de donnée en base de données train pour faire l'entrainement et une base de données test afin d'éviter de l'overfitting. 80% de notre data est pris pour la base de données test alors que les 20% finaux sont conservées pour la bdd test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and test data\n",
    "train_start = 0\n",
    "train_end = int(np.floor(0.8*n))\n",
    "test_start = train_end\n",
    "test_end = n\n",
    "data_train = data[np.arange(train_start, train_end), :]\n",
    "data_test = data[np.arange(test_start, test_end), :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de set nos données nous avons scale les informations pour les initializer et scale les données test en fonction de ces données de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data_train = scaler.fit_transform(data_train)\n",
    "data_test = scaler.transform(data_test)\n",
    "# Build X and y\n",
    "X_train = data_train[:, 1:]\n",
    "y_train = data_train[:, 0]\n",
    "X_test = data_test[:, 1:]\n",
    "y_test = data_test[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre réseau de données a une architecture de 4 hidden layers (1024,512,256,126) avec comme fonction d'activation 'relu' avec un dropout de 0.1 qui réduit l'overfitting et nous renvoie un mse diminué par rapport à un model sans dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, input_dim=500, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme la variable cible est une variable continue et on cherche une relation linéaire, nous avons décidé de prendre comme loss MSE avec comme optimizer ADAM afin d'avoir un gradient déscendant ni trop lent ni trop rapide et ne pas être coincé dans un point selle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait fit notre model avec un propagation et une retropropagation avec 10 itération de toute la données sur des batches de tailles 256 afin de réaliser notre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "33012/33012 [==============================] - 4s 112us/step - loss: 0.0837 - mse: 0.0837\n",
      "Epoch 2/10\n",
      "33012/33012 [==============================] - 4s 108us/step - loss: 9.1108e-04 - mse: 9.1108e-04\n",
      "Epoch 3/10\n",
      "33012/33012 [==============================] - 3s 106us/step - loss: 6.8883e-04 - mse: 6.8883e-04\n",
      "Epoch 4/10\n",
      "33012/33012 [==============================] - 4s 108us/step - loss: 5.2977e-04 - mse: 5.2977e-04\n",
      "Epoch 5/10\n",
      "33012/33012 [==============================] - 3s 106us/step - loss: 4.9124e-04 - mse: 4.9124e-04\n",
      "Epoch 6/10\n",
      "33012/33012 [==============================] - 3s 106us/step - loss: 4.7452e-04 - mse: 4.7452e-04\n",
      "Epoch 7/10\n",
      "33012/33012 [==============================] - 4s 109us/step - loss: 3.7035e-04 - mse: 3.7035e-04\n",
      "Epoch 8/10\n",
      "33012/33012 [==============================] - 4s 106us/step - loss: 3.8600e-04 - mse: 3.8600e-04\n",
      "Epoch 9/10\n",
      "33012/33012 [==============================] - 4s 113us/step - loss: 3.4426e-04 - mse: 3.4425e-04\n",
      "Epoch 10/10\n",
      "33012/33012 [==============================] - 4s 112us/step - loss: 3.5808e-04 - mse: 3.5808e-04 1s - los\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c100b1a688>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8254/8254 [==============================] - 1s 86us/step\n",
      "MSE: 0.003234\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('MSE: %.6f' % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
